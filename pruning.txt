Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | total_pruned =     512 | shape = (50265, 512)alive: 25735168, pruned : 512, total: 25735680, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | total_pruned =     512 | shape = (514, 512)alive: 25997824, pruned : 1024, total: 25998848, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26259968, pruned : 1024, total: 26260992, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26259968, pruned : 1536, total: 26261504, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26522112, pruned : 1536, total: 26523648, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26522112, pruned : 2048, total: 26524160, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26784256, pruned : 2048, total: 26786304, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26784256, pruned : 2560, total: 26786816, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 27046400, pruned : 2560, total: 27048960, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 27046400, pruned : 3072, total: 27049472, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 27046912, pruned : 3072, total: 27049984, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 27046912, pruned : 3584, total: 27050496, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 27571200, pruned : 3584, total: 27574784, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 27571200, pruned : 4608, total: 27575808, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 28095488, pruned : 4608, total: 28100096, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28095488, pruned : 5120, total: 28100608, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 28096000, pruned : 5120, total: 28101120, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28096000, pruned : 5632, total: 28101632, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28358144, pruned : 5632, total: 28363776, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28358144, pruned : 6144, total: 28364288, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28620288, pruned : 6144, total: 28626432, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28620288, pruned : 6656, total: 28626944, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28882432, pruned : 6656, total: 28889088, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28882432, pruned : 7168, total: 28889600, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 29144576, pruned : 7168, total: 29151744, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 29144576, pruned : 7680, total: 29152256, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 29145088, pruned : 7680, total: 29152768, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 29145088, pruned : 8192, total: 29153280, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 29669376, pruned : 8192, total: 29677568, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 29669376, pruned : 9216, total: 29678592, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 30193664, pruned : 9216, total: 30202880, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30193664, pruned : 9728, total: 30203392, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 30194176, pruned : 9728, total: 30203904, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30194176, pruned : 10240, total: 30204416, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30456320, pruned : 10240, total: 30466560, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30456320, pruned : 10752, total: 30467072, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30718464, pruned : 10752, total: 30729216, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30718464, pruned : 11264, total: 30729728, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30980608, pruned : 11264, total: 30991872, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30980608, pruned : 11776, total: 30992384, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 31242752, pruned : 11776, total: 31254528, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 31242752, pruned : 12288, total: 31255040, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 31243264, pruned : 12288, total: 31255552, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 31243264, pruned : 12800, total: 31256064, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 31767552, pruned : 12800, total: 31780352, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 31767552, pruned : 13824, total: 31781376, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 32291840, pruned : 13824, total: 32305664, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32291840, pruned : 14336, total: 32306176, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 32292352, pruned : 14336, total: 32306688, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32292352, pruned : 14848, total: 32307200, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 32554496, pruned : 14848, total: 32569344, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32554496, pruned : 15360, total: 32569856, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 32816640, pruned : 15360, total: 32832000, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32816640, pruned : 15872, total: 32832512, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 33078784, pruned : 15872, total: 33094656, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33078784, pruned : 16384, total: 33095168, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 33340928, pruned : 16384, total: 33357312, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33340928, pruned : 16896, total: 33357824, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 33341440, pruned : 16896, total: 33358336, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33341440, pruned : 17408, total: 33358848, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 33865728, pruned : 17408, total: 33883136, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 33865728, pruned : 18432, total: 33884160, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 34390016, pruned : 18432, total: 34408448, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34390016, pruned : 18944, total: 34408960, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 34390528, pruned : 18944, total: 34409472, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34390528, pruned : 19456, total: 34409984, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 34652672, pruned : 19456, total: 34672128, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34652672, pruned : 19968, total: 34672640, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 34914816, pruned : 19968, total: 34934784, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34914816, pruned : 20480, total: 34935296, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 35176960, pruned : 20480, total: 35197440, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35176960, pruned : 20992, total: 35197952, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 35439104, pruned : 20992, total: 35460096, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35439104, pruned : 21504, total: 35460608, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 35439616, pruned : 21504, total: 35461120, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35439616, pruned : 22016, total: 35461632, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 35963904, pruned : 22016, total: 35985920, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 35963904, pruned : 23040, total: 35986944, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 36488192, pruned : 23040, total: 36511232, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36488192, pruned : 23552, total: 36511744, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 36488704, pruned : 23552, total: 36512256, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36488704, pruned : 24064, total: 36512768, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 36750848, pruned : 24064, total: 36774912, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36750848, pruned : 24576, total: 36775424, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37012992, pruned : 24576, total: 37037568, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37012992, pruned : 25088, total: 37038080, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37275136, pruned : 25088, total: 37300224, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37275136, pruned : 25600, total: 37300736, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37537280, pruned : 25600, total: 37562880, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37537280, pruned : 26112, total: 37563392, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 37537792, pruned : 26112, total: 37563904, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37537792, pruned : 26624, total: 37564416, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 38062080, pruned : 26624, total: 38088704, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 38062080, pruned : 27648, total: 38089728, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 38586368, pruned : 27648, total: 38614016, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38586368, pruned : 28160, total: 38614528, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38586880, pruned : 28160, total: 38615040, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38586880, pruned : 28672, total: 38615552, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38587392, pruned : 28672, total: 38616064, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38587392, pruned : 29184, total: 38616576, Compression rate :       1.00x  (  0.08% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | total_pruned =   50265 | shape = (50265,)alive: 38587392, pruned : 79449, total: 38666841, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 38849536, pruned : 79449, total: 38928985, Compression rate :       1.00x  (  0.20% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38849536, pruned : 79961, total: 38929497, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38850048, pruned : 79961, total: 38930009, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38850048, pruned : 80473, total: 38930521, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | total_pruned =     512 | shape = (50265, 512)alive: 25735168, pruned : 512, total: 25735680, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | total_pruned =     512 | shape = (514, 512)alive: 25997824, pruned : 1024, total: 25998848, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26259968, pruned : 1024, total: 26260992, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26259968, pruned : 1536, total: 26261504, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26522112, pruned : 1536, total: 26523648, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26522112, pruned : 2048, total: 26524160, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26784256, pruned : 2048, total: 26786304, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26784256, pruned : 2560, total: 26786816, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 27046400, pruned : 2560, total: 27048960, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 27046400, pruned : 3072, total: 27049472, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 27046912, pruned : 3072, total: 27049984, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 27046912, pruned : 3584, total: 27050496, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 27571200, pruned : 3584, total: 27574784, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 27571200, pruned : 4608, total: 27575808, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 28095488, pruned : 4608, total: 28100096, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28095488, pruned : 5120, total: 28100608, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 28096000, pruned : 5120, total: 28101120, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28096000, pruned : 5632, total: 28101632, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28358144, pruned : 5632, total: 28363776, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28358144, pruned : 6144, total: 28364288, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28620288, pruned : 6144, total: 28626432, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28620288, pruned : 6656, total: 28626944, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28882432, pruned : 6656, total: 28889088, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28882432, pruned : 7168, total: 28889600, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 29144576, pruned : 7168, total: 29151744, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 29144576, pruned : 7680, total: 29152256, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 29145088, pruned : 7680, total: 29152768, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 29145088, pruned : 8192, total: 29153280, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 29669376, pruned : 8192, total: 29677568, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 29669376, pruned : 9216, total: 29678592, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 30193664, pruned : 9216, total: 30202880, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30193664, pruned : 9728, total: 30203392, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 30194176, pruned : 9728, total: 30203904, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30194176, pruned : 10240, total: 30204416, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30456320, pruned : 10240, total: 30466560, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30456320, pruned : 10752, total: 30467072, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30718464, pruned : 10752, total: 30729216, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30718464, pruned : 11264, total: 30729728, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30980608, pruned : 11264, total: 30991872, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30980608, pruned : 11776, total: 30992384, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 31242752, pruned : 11776, total: 31254528, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 31242752, pruned : 12288, total: 31255040, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 31243264, pruned : 12288, total: 31255552, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 31243264, pruned : 12800, total: 31256064, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 31767552, pruned : 12800, total: 31780352, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 31767552, pruned : 13824, total: 31781376, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 32291840, pruned : 13824, total: 32305664, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32291840, pruned : 14336, total: 32306176, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 32292352, pruned : 14336, total: 32306688, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32292352, pruned : 14848, total: 32307200, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 32554496, pruned : 14848, total: 32569344, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32554496, pruned : 15360, total: 32569856, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 32816640, pruned : 15360, total: 32832000, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32816640, pruned : 15872, total: 32832512, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 33078784, pruned : 15872, total: 33094656, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33078784, pruned : 16384, total: 33095168, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 33340928, pruned : 16384, total: 33357312, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33340928, pruned : 16896, total: 33357824, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 33341440, pruned : 16896, total: 33358336, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33341440, pruned : 17408, total: 33358848, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 33865728, pruned : 17408, total: 33883136, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 33865728, pruned : 18432, total: 33884160, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 34390016, pruned : 18432, total: 34408448, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34390016, pruned : 18944, total: 34408960, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 34390528, pruned : 18944, total: 34409472, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34390528, pruned : 19456, total: 34409984, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 34652672, pruned : 19456, total: 34672128, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34652672, pruned : 19968, total: 34672640, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 34914816, pruned : 19968, total: 34934784, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34914816, pruned : 20480, total: 34935296, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 35176960, pruned : 20480, total: 35197440, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35176960, pruned : 20992, total: 35197952, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 35439104, pruned : 20992, total: 35460096, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35439104, pruned : 21504, total: 35460608, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 35439616, pruned : 21504, total: 35461120, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35439616, pruned : 22016, total: 35461632, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 35963904, pruned : 22016, total: 35985920, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 35963904, pruned : 23040, total: 35986944, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 36488192, pruned : 23040, total: 36511232, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36488192, pruned : 23552, total: 36511744, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 36488704, pruned : 23552, total: 36512256, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36488704, pruned : 24064, total: 36512768, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 36750848, pruned : 24064, total: 36774912, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36750848, pruned : 24576, total: 36775424, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37012992, pruned : 24576, total: 37037568, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37012992, pruned : 25088, total: 37038080, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37275136, pruned : 25088, total: 37300224, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37275136, pruned : 25600, total: 37300736, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37537280, pruned : 25600, total: 37562880, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37537280, pruned : 26112, total: 37563392, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 37537792, pruned : 26112, total: 37563904, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37537792, pruned : 26624, total: 37564416, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 38062080, pruned : 26624, total: 38088704, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 38062080, pruned : 27648, total: 38089728, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 38586368, pruned : 27648, total: 38614016, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38586368, pruned : 28160, total: 38614528, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38586880, pruned : 28160, total: 38615040, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38586880, pruned : 28672, total: 38615552, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38587392, pruned : 28672, total: 38616064, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38587392, pruned : 29184, total: 38616576, Compression rate :       1.00x  (  0.08% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | total_pruned =   50265 | shape = (50265,)alive: 38587392, pruned : 79449, total: 38666841, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 38849536, pruned : 79449, total: 38928985, Compression rate :       1.00x  (  0.20% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38849536, pruned : 79961, total: 38929497, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38850048, pruned : 79961, total: 38930009, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38850048, pruned : 80473, total: 38930521, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | total_pruned =     512 | shape = (50265, 512)alive: 25735168, pruned : 512, total: 25735680, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | total_pruned =     512 | shape = (514, 512)alive: 25997824, pruned : 1024, total: 25998848, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26259968, pruned : 1024, total: 26260992, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26259968, pruned : 1536, total: 26261504, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26522112, pruned : 1536, total: 26523648, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26522112, pruned : 2048, total: 26524160, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 26784256, pruned : 2048, total: 26786304, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 26784256, pruned : 2560, total: 26786816, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 27046400, pruned : 2560, total: 27048960, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 27046400, pruned : 3072, total: 27049472, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 27046912, pruned : 3072, total: 27049984, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 27046912, pruned : 3584, total: 27050496, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 27571200, pruned : 3584, total: 27574784, Compression rate :       1.00x  (  0.01% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 27571200, pruned : 4608, total: 27575808, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 28095488, pruned : 4608, total: 28100096, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28095488, pruned : 5120, total: 28100608, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 28096000, pruned : 5120, total: 28101120, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28096000, pruned : 5632, total: 28101632, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28358144, pruned : 5632, total: 28363776, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28358144, pruned : 6144, total: 28364288, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28620288, pruned : 6144, total: 28626432, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28620288, pruned : 6656, total: 28626944, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 28882432, pruned : 6656, total: 28889088, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 28882432, pruned : 7168, total: 28889600, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 29144576, pruned : 7168, total: 29151744, Compression rate :       1.00x  (  0.02% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 29144576, pruned : 7680, total: 29152256, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 29145088, pruned : 7680, total: 29152768, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 29145088, pruned : 8192, total: 29153280, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 29669376, pruned : 8192, total: 29677568, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 29669376, pruned : 9216, total: 29678592, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 30193664, pruned : 9216, total: 30202880, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30193664, pruned : 9728, total: 30203392, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 30194176, pruned : 9728, total: 30203904, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30194176, pruned : 10240, total: 30204416, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30456320, pruned : 10240, total: 30466560, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30456320, pruned : 10752, total: 30467072, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30718464, pruned : 10752, total: 30729216, Compression rate :       1.00x  (  0.03% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30718464, pruned : 11264, total: 30729728, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 30980608, pruned : 11264, total: 30991872, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 30980608, pruned : 11776, total: 30992384, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 31242752, pruned : 11776, total: 31254528, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 31242752, pruned : 12288, total: 31255040, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 31243264, pruned : 12288, total: 31255552, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 31243264, pruned : 12800, total: 31256064, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 31767552, pruned : 12800, total: 31780352, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 31767552, pruned : 13824, total: 31781376, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 32291840, pruned : 13824, total: 32305664, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32291840, pruned : 14336, total: 32306176, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 32292352, pruned : 14336, total: 32306688, Compression rate :       1.00x  (  0.04% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32292352, pruned : 14848, total: 32307200, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 32554496, pruned : 14848, total: 32569344, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32554496, pruned : 15360, total: 32569856, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 32816640, pruned : 15360, total: 32832000, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 32816640, pruned : 15872, total: 32832512, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 33078784, pruned : 15872, total: 33094656, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33078784, pruned : 16384, total: 33095168, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 33340928, pruned : 16384, total: 33357312, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33340928, pruned : 16896, total: 33357824, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 33341440, pruned : 16896, total: 33358336, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 33341440, pruned : 17408, total: 33358848, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 33865728, pruned : 17408, total: 33883136, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 33865728, pruned : 18432, total: 33884160, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 34390016, pruned : 18432, total: 34408448, Compression rate :       1.00x  (  0.05% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34390016, pruned : 18944, total: 34408960, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 34390528, pruned : 18944, total: 34409472, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34390528, pruned : 19456, total: 34409984, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 34652672, pruned : 19456, total: 34672128, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34652672, pruned : 19968, total: 34672640, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 34914816, pruned : 19968, total: 34934784, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 34914816, pruned : 20480, total: 34935296, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 35176960, pruned : 20480, total: 35197440, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35176960, pruned : 20992, total: 35197952, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 35439104, pruned : 20992, total: 35460096, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35439104, pruned : 21504, total: 35460608, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 35439616, pruned : 21504, total: 35461120, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 35439616, pruned : 22016, total: 35461632, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 35963904, pruned : 22016, total: 35985920, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 35963904, pruned : 23040, total: 35986944, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 36488192, pruned : 23040, total: 36511232, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36488192, pruned : 23552, total: 36511744, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 36488704, pruned : 23552, total: 36512256, Compression rate :       1.00x  (  0.06% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36488704, pruned : 24064, total: 36512768, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 36750848, pruned : 24064, total: 36774912, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 36750848, pruned : 24576, total: 36775424, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37012992, pruned : 24576, total: 37037568, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37012992, pruned : 25088, total: 37038080, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37275136, pruned : 25088, total: 37300224, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37275136, pruned : 25600, total: 37300736, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 37537280, pruned : 25600, total: 37562880, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37537280, pruned : 26112, total: 37563392, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 37537792, pruned : 26112, total: 37563904, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 37537792, pruned : 26624, total: 37564416, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (1024, 512)alive: 38062080, pruned : 26624, total: 38088704, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | total_pruned =    1024 | shape = (1024,)alive: 38062080, pruned : 27648, total: 38089728, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | total_pruned =       0 | shape = (512, 1024)alive: 38586368, pruned : 27648, total: 38614016, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38586368, pruned : 28160, total: 38614528, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38586880, pruned : 28160, total: 38615040, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38586880, pruned : 28672, total: 38615552, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38587392, pruned : 28672, total: 38616064, Compression rate :       1.00x  (  0.07% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38587392, pruned : 29184, total: 38616576, Compression rate :       1.00x  (  0.08% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | total_pruned =   50265 | shape = (50265,)alive: 38587392, pruned : 79449, total: 38666841, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | total_pruned =       0 | shape = (512, 512)alive: 38849536, pruned : 79449, total: 38928985, Compression rate :       1.00x  (  0.20% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38849536, pruned : 79961, total: 38929497, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | total_pruned =       0 | shape = (512,)alive: 38850048, pruned : 79961, total: 38930009, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | total_pruned =     512 | shape = (512,)alive: 38850048, pruned : 80473, total: 38930521, Compression rate :       1.00x  (  0.21% pruned)
 
 
 
 Iteration: 0
 
{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%
 nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Compression rate :       3.09x  ( 67.66% pruned)
 
 
 
 Iteration: 0
 
{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = {total_params_mask - nz_count_mask :7} | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%
 nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Compression rate :       3.09x  ( 67.66% pruned)
 
 
 
 Iteration: 0
 
{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}{name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,){name:20} | nonzeros = {nz_count:7} / {total_params:7} ({100 * nz_count / total_params:6.2f}%) | zeros = {total_params - nz_count :7} | pruned = 0 | shape = {tensor.shape}nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%
 nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Compression rate :       3.09x  ( 67.66% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | zeros =     512 | pruned = 0 | shape = (50265, 512)decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | zeros =     512 | pruned = 0 | shape = (514, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | zeros =   50265 | pruned = 0 | shape = (50265,)decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned = 0 | shape = (512, 512)decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%
 nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Compression rate :       3.09x  ( 67.66% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | zeros =     512 | pruned = 0 | shape = (50265, 512)decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | zeros =     512 | pruned = 0 | shape = (514, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | zeros =   50265 | pruned = 0 | shape = (50265,)decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned = 0 | shape = (512, 512)decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%
 nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Compression rate :       1.00x  (  0.00% pruned)
 
 
 
 Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | zeros =     512 | pruned = 0 | shape = (50265, 512)decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | zeros =     512 | pruned = 0 | shape = (514, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | zeros =   50265 | pruned = 0 | shape = (50265,)decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned = 0 | shape = (512, 512)decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Considered weights for prune: 12590080 / 38930521 ( 32.34%) | Compression rate :       1.00x  (  0.00% pruned)


Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | zeros =     512 | pruned = 0 | shape = (50265, 512)decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | zeros =     512 | pruned = 0 | shape = (514, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | zeros =   50265 | pruned = 0 | shape = (50265,)decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned = 0 | shape = (512, 512)decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Considered weights for prune: 12590080 / 38930521 ( 32.34%) | Remained weights : (100.00% of considerd weights) | ( 32.34% of all weights)


Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | zeros =     512 | pruned = 0 | shape = (50265, 512)decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | zeros =     512 | pruned = 0 | shape = (514, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | zeros =   50265 | pruned = 0 | shape = (50265,)decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned = 0 | shape = (512, 512)decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Considered weights for prune: 12590080 / 38930521 ( 32.34%) | Pruned weights : (  0.00% of considered weights) | (  0.00% of all weights)


Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | zeros =     512 | pruned = 0 | shape = (50265, 512)decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | zeros =     512 | pruned = 0 | shape = (514, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | zeros =   50265 | pruned = 0 | shape = (50265,)decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned = 0 | shape = (512, 512)decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Considered weights for prune: 12590080 / 38930521 ( 32.34%) | Pruned weights : (  0.00% of considered weights) | (  0.00% of all weights)


Iteration: 0
 
decoder.sentence_encoder.embed_tokens.weight | nonzeros = 25735168 / 25735680 (100.00%) | zeros =     512 | pruned = 0 | shape = (50265, 512)decoder.sentence_encoder.embed_positions.weight | nonzeros =  262656 /  263168 ( 99.81%) | zeros =     512 | pruned = 0 | shape = (514, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.0.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.0.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.0.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.0.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.0.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.1.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.1.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.1.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.1.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.1.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.2.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.2.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.2.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.2.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.2.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.3.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.3.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.3.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.3.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.3.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.4.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.4.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.4.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.4.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.4.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.k_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.k_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.v_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.v_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.q_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.q_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn.out_proj.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 512)decoder.sentence_encoder.layers.5.self_attn.out_proj.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.self_attn_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.fc1.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (1024, 512)decoder.sentence_encoder.layers.5.fc1.bias | nonzeros =       0 /    1024 (  0.00%) | zeros =    1024 | pruned = 0 | shape = (1024,)decoder.sentence_encoder.layers.5.fc2.weight | nonzeros =  524288 /  524288 (100.00%) | zeros =       0 | pruned =       0 | shape = (512, 1024)decoder.sentence_encoder.layers.5.fc2.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.layers.5.final_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.sentence_encoder.emb_layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.bias | nonzeros =       0 /   50265 (  0.00%) | zeros =   50265 | pruned = 0 | shape = (50265,)decoder.lm_head.dense.weight | nonzeros =  262144 /  262144 (100.00%) | zeros =       0 | pruned = 0 | shape = (512, 512)decoder.lm_head.dense.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)decoder.lm_head.layer_norm.weight | nonzeros =     512 /     512 (100.00%) | zeros =       0 | pruned =       0 | shape = (512,)decoder.lm_head.layer_norm.bias | nonzeros =       0 /     512 (  0.00%) | zeros =     512 | pruned = 0 | shape = (512,)nonzero: 38850048, zero : 80473, total: 38930521, Zeros:   0.21%nonzero mask: 12590080, pruned : 0, total mask: 12590080, total: 38930521, Considered weights for prune: 12590080 / 38930521 ( 32.34%) | Pruned weights : (  0.00% of considered weights) | (  0.00% of all weights)


